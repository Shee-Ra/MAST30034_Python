{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 Overview\n",
    "## First Half\n",
    "- Linear Regression.\n",
    "- Evaluation Metrics.\n",
    "- Penalized Regression (LASSO and Ridge).\n",
    "- Generalised Linear Models (GLM).\n",
    "- Discussion.\n",
    "\n",
    "## Second Half\n",
    "Revision:\n",
    "- Any code related questions for Python.\n",
    "- (Windows 10 Users) Installing WSL2 (Ubuntu 20.04) for a clean environment.\n",
    "\n",
    "Advanced Content:\n",
    "- Introduction to `PySpark` continued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression in Python\n",
    "- Linear Regression.\n",
    "- General Linear Models (more covered in MAST30027).\n",
    "- LASSO and Ridge Regression .\n",
    "- Non-parametric models as alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from statsmodels.formula.api import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                   int64\n",
       "tpep_pickup_datetime      object\n",
       "tpep_dropoff_datetime     object\n",
       "passenger_count            int64\n",
       "trip_distance            float64\n",
       "pickup_longitude         float64\n",
       "pickup_latitude          float64\n",
       "RatecodeID                 int64\n",
       "store_and_fwd_flag        object\n",
       "dropoff_longitude        float64\n",
       "dropoff_latitude         float64\n",
       "payment_type               int64\n",
       "fare_amount              float64\n",
       "extra                    float64\n",
       "mta_tax                  float64\n",
       "tip_amount               float64\n",
       "tolls_amount             float64\n",
       "improvement_surcharge    float64\n",
       "total_amount             float64\n",
       "pickupX                  float64\n",
       "pickupY                  float64\n",
       "dropoffX                 float64\n",
       "dropoffY                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../data/lab_specific/sample.pkl\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's try to predict `total_amount` using `fare_amount, tip_amount, toll_amount, trip_distance, VendorID` as predictors.\n",
    "\n",
    "Some things to take note:\n",
    "- `tip_amount` is only valid for `payment_type == 1` (card)\n",
    "- `VendorID` is categorical, with only two possible values (`1` or `2`) so we should make it boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_amount</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>VendorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65616</th>\n",
       "      <td>38.68</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>5.54</td>\n",
       "      <td>9.88</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65617</th>\n",
       "      <td>45.80</td>\n",
       "      <td>38.5</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.75</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65618</th>\n",
       "      <td>8.75</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65619</th>\n",
       "      <td>23.76</td>\n",
       "      <td>18.5</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.73</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65620</th>\n",
       "      <td>6.96</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_amount  fare_amount  tip_amount  tolls_amount  trip_distance  \\\n",
       "65616         38.68         30.0        1.84          5.54           9.88   \n",
       "65617         45.80         38.5        6.00          0.00          12.75   \n",
       "65618          8.75          6.0        1.45          0.00           0.80   \n",
       "65619         23.76         18.5        3.96          0.00           4.73   \n",
       "65620          6.96          4.5        1.16          0.00           0.80   \n",
       "\n",
       "       VendorID  \n",
       "65616     False  \n",
       "65617     False  \n",
       "65618      True  \n",
       "65619     False  \n",
       "65620     False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter dataframe\n",
    "COL_FILTER = ['total_amount', 'fare_amount', 'tip_amount', 'tolls_amount', 'trip_distance', 'VendorID']\n",
    "df_filtered = df.loc[df['payment_type'] == 1, COL_FILTER].reset_index(drop=True)\n",
    "\n",
    "# same as df_filtered['VendorID'].astype(bool)\n",
    "df_filtered['VendorID'] = df_filtered['VendorID'] == 1 \n",
    "\n",
    "df_filtered.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are looking for linear relationships between our chosen response `total_amount`.   \n",
    "- Now I'm not sure what kind of life you've lived, but I'm fairly certain that we can infer that `total_amount` will have a positive linear relationship with `fare_amount`. Let's see a quick plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_filtered[['total_amount', 'fare_amount']].plot.scatter(x='fare_amount', y='total_amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, obviously this looks like an overall positive linear relationship.\n",
    "- How might we statistically test this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In R, we would do something like this for (Ordinary) Least Squares:\n",
    "```R\n",
    ">>> fit <- lm(total_amount~fare_amount + tip_amount + tolls_amount + trip_distance + VendorID ,data=dat_fit)\n",
    ">>> summary(fit)\n",
    "```\n",
    "```\n",
    "Call:\n",
    "lm(formula = total_amount ~ fare_amount + tip_amount + tolls_amount +\n",
    "trip_distance + VendorID, data = dat_fit)\n",
    "\n",
    "Residuals:\n",
    "Min     1Q      Median  3Q     Max\n",
    "-1.4727 -0.3295 -0.1528 0.1747 1.7975\n",
    "\n",
    "Coefficients:\n",
    "               Estimate Std. Error t value Pr(>|t|)\n",
    "(Intercept)    1.162154   0.002986 389.194  <2e-16 ***\n",
    "fare_amount    0.993388   0.000315 3153.943 <2e-16 ***\n",
    "tip_amount     1.006511   0.000826 1218.553 <2e-16 ***\n",
    "tolls_amount   0.979325   0.001285 762.428  <2e-16 ***\n",
    "trip_distance  0.011742   0.000963 12.194   <2e-16 ***\n",
    "VendorIDTRUE  -0.003125   0.002914 -1.073    0.283\n",
    "---\n",
    "Signif. codes:\n",
    "0 ^a˘A¨Y***^a˘A´Z 0.001 ^a˘A¨Y**^a˘A´Z 0.01 ^a˘A¨Y*^a˘A´Z 0.05 ^a˘A¨Y.^a˘A´Z 0.1 ^a˘A¨Y ^a˘A´Z 1\n",
    "\n",
    "Residual standard error: 0.362 on 61886 degrees of freedom\n",
    "Multiple R-squared: 0.9994,          Adjusted R-squared: 0.9994\n",
    "F-statistic: 1.953e+07 on 5 and 61886 DF, p-value: < 2.2e-16\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, whatever you can do in R can also done in Python (to an extent).  \n",
    "Documentation Source: https://www.statsmodels.org/dev/generated/statsmodels.formula.api.ols.html?highlight=ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = ols(formula=\"total_amount ~ fare_amount + tip_amount + tolls_amount + trip_distance + VendorID\",\n",
    "         data=df_filtered).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           total_amount   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 4.113e+07\n",
      "Date:                Mon, 07 Jun 2021   Prob (F-statistic):               0.00\n",
      "Time:                        13:40:05   Log-Likelihood:                 5322.1\n",
      "No. Observations:               65621   AIC:                        -1.063e+04\n",
      "Df Residuals:                   65615   BIC:                        -1.058e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            1.4654      0.002    791.722      0.000       1.462       1.469\n",
      "VendorID[T.True]    -0.0096      0.002     -5.500      0.000      -0.013      -0.006\n",
      "fare_amount          0.9959      0.000   4687.794      0.000       0.995       0.996\n",
      "tip_amount           1.0054      0.001   1695.304      0.000       1.004       1.007\n",
      "tolls_amount         0.9910      0.001   1148.462      0.000       0.989       0.993\n",
      "trip_distance       -0.0051      0.001     -8.257      0.000      -0.006      -0.004\n",
      "==============================================================================\n",
      "Omnibus:                     6787.253   Durbin-Watson:                   0.413\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9105.878\n",
      "Skew:                           0.904   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.243   Cond. No.                         43.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The table structure is a bit different, though it is identical in value with R's output.  \n",
    "- The coefficient table is the same, but now includes a 95% CI for the beta coefficients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Is this model good?\n",
    "    - The $R^2$ value is 0.999 which is insanely large. As a rule of thumb, large $R^2$ values indicate a good fit. \n",
    "    - *Perhaps too good of a fit...*\n",
    "    - AIC itself isn't important, however, if we compare it to another model (let's say an alternative model with different features chosen)...\n",
    "    - If we have a hypothesis for a null model ($\\beta=0$) vs our fitted model ($\\beta\\neq0$), then we can look at the `F-statistc = 1.953e+07`. The corresponding p-value of  this F statistic is `0.00`, which is less than $\\alpha=0.05$, so we can conclude that our fitted model is better than a null model. In other words, we reject the null hypothesis and conclude that we believe the intercept parameters to be non-zero.\n",
    "    \n",
    "    \n",
    "- How might we improve this model?\n",
    "    - If we look at the parameters, we may wish to exclude `VendorID[T.True]` as it is not significant with p-value `0.283 > 0.05`. Perhaps we should drop this attribute and fit another model without it.\n",
    "    - Additionally, we can do some feature engineering (run a decision tree and look at the splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           total_amount   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 6.844e+07\n",
      "Date:                Mon, 07 Jun 2021   Prob (F-statistic):               0.00\n",
      "Time:                        13:40:05   Log-Likelihood:                 5273.9\n",
      "No. Observations:               65621   AIC:                        -1.054e+04\n",
      "Df Residuals:                   65617   BIC:                        -1.050e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept        1.4657      0.002    940.683      0.000       1.463       1.469\n",
      "fare_amount      0.9946      0.000   7184.782      0.000       0.994       0.995\n",
      "tip_amount       1.0047      0.001   1711.771      0.000       1.004       1.006\n",
      "tolls_amount     0.9894      0.001   1173.671      0.000       0.988       0.991\n",
      "==============================================================================\n",
      "Omnibus:                     6960.903   Durbin-Watson:                   0.408\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9427.364\n",
      "Skew:                           0.924   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.189   Cond. No.                         31.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "fitter = ols(formula=\"total_amount ~ fare_amount + tip_amount + tolls_amount\",\n",
    "         data=df_filtered).fit()\n",
    "print(fitter.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have to values of AIC to compare with, which one is better...?\n",
    "- Well, we see a small decrease in AIC and a large decrease in BIC. Hence, we can say that the model without `VendorID` is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-10632.271532677914, -10539.899110559505],\n",
       " [-10577.721626403982, -10503.532506376883])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fit.aic, fitter.aic], [fit.bic, fitter.bic]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalized Regression\n",
    "- LASSO (l1) and Ridge (l2) Regression\n",
    "\n",
    "Revise in your own time if you've forgotten (this was covered in MAST30025):\n",
    "- Lecture 4 (variable selection)\n",
    "- LSM topic 5 (`ch05_handout`) slide 141/141\n",
    "\n",
    "Things you might have forgotten when working with penalized models:\n",
    "- Always good to standardize your data prior to train and test. Most models perform poorly if not standardized prior. \n",
    "- Do not fit your standardizer to test, only to train. You should transform both your train and test though.\n",
    "\n",
    "### LASSO ($\\ell_1$)\n",
    "Quick overview:\n",
    "- LASSO may cause coefficients to be set to 0 by constraining the model.\n",
    "- This is because we put a constraint where the sum of the absolute values of the coefficients must be less than some fixed value. \n",
    "- As such, some coefficients may end up having 0 which is the same as *dropping* the attribute from the model.\n",
    "- In this sense, it's quite similar to feature selection as you end up with a model that is much more simpler. \n",
    "- However, LASSO does not do well when the feature space is small as you may end up with an over-simplified model, as well as cases where all the featuers are significant or when coefficients are extremely large. \n",
    "\n",
    "Solution:\n",
    "- Requires an iterative method to solve $(\\mathbf{y}-X\\beta)^T(\\mathbf{y}-X\\beta) + \\lambda I \\beta$\n",
    "\n",
    "### Ridge ($\\ell_2$)\n",
    "Quick overview:\n",
    "- Also know as the MAP (Maximum a posteriori) estimation.\n",
    "- Aims to lower the scale of the coefficients to avoid overfitting, but does not result in coefficients being 0.\n",
    "- In contraast to LASSO, we put a constrain using the sum of squares that must be lest than a fixed value. \n",
    "- As you might guess, this means we still have several features making it less interpretable than LASSO.\n",
    "- However, Ridge Regression performs best in cases where there may be high multi-colinearity (i.e dependencies between attributes) or high linear correlation between certain attributes,\n",
    "- This is because it reduces variance in exchange for some more bias (consider variance-bias tradeoff).\n",
    "- You must also ensure that we have more observations than attributes (`n > p`) as this penalty method does not drop features, leading to worse predictions. \n",
    "\n",
    "Solution:\n",
    "- Closed-form which can be found by minimising $(\\mathbf{y}-X\\beta)^T(\\mathbf{y}-X\\beta) + \\lambda I \\beta^T\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yCOLS = ['total_amount']\n",
    "xCOLS = ['fare_amount', 'tip_amount', 'tolls_amount', 'trip_distance', 'VendorID']\n",
    "\n",
    "# standardize (by calculating the zscore) so our data has mean 0 and var 1\n",
    "# alternatively, you can use sklearn's StandardScalar\n",
    "\n",
    "from scipy.stats import zscore\n",
    "df_standard = df_filtered[xCOLS].astype(float).apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>VendorID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fare_amount  tip_amount  tolls_amount  trip_distance  VendorID\n",
       "mean      -0.0000      0.0000        0.0000         0.0000    0.0000\n",
       "std        1.0000      1.0000        1.0000         1.0000    1.0000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format output to 4 decimal places\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "df_standard.describe().loc[['mean','std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `df_standard` has  $\\mu=0, \\sigma=1(=\\sigma^2)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glmnet import ElasticNet\n",
    "\n",
    "lasso_fit = ElasticNet()\n",
    "lasso_fit.fit(df_standard.values, df_filtered[yCOLS].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to look at the shrinking parameter $\\lambda$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lambda value for LASSO: 0.27198196216152276\n"
     ]
    }
   ],
   "source": [
    "# this can be accessed using the .lambda_best_ method after fitting!\n",
    "print(f'Best lambda value for LASSO: {lasso_fit.lambda_best_[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\lambda$ is computed by using cross validation (iterative approach)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about our coefficients?\n",
    "- https://github.com/civisanalytics/python-glmnet/blob/master/glmnet/linear.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>17.5665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare_amount</th>\n",
       "      <td>9.8504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tip_amount</th>\n",
       "      <td>2.1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolls_amount</th>\n",
       "      <td>1.0554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_distance</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VendorID</th>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coefficient\n",
       "Intercept          17.5665\n",
       "fare_amount         9.8504\n",
       "tip_amount          2.1925\n",
       "tolls_amount        1.0554\n",
       "trip_distance       0.0000\n",
       "VendorID            0.0000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(index = ['Intercept'] + xCOLS, \n",
    "             data= [lasso_fit.intercept_] + list(lasso_fit.coef_), \n",
    "             columns = ['Coefficient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `trip_distance` and `VendorID` have *shrunk* to 0. You can use `lasso_fit.predict(x)` to the predict a new set of observations by passing through the `x` matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a GLM (Optional)\n",
    "- Well, this is exactly what some of you will be learning in MAST30027 right now.\n",
    "\n",
    "Let's go through an example:\n",
    "- The `passenger_count` attribute is discrete and non-negative. If we were to predict it, a linear model will not be sufficient. \n",
    "- We know that a Poisson distribution takes in non-negative integer values, so we can use the Poisson family of GLMs to model this. \n",
    "- We will use `total_amount, trip_distance, VendorID` as our regressors.\n",
    "\n",
    "For those of you not taking MAST30027 (ELI5):\n",
    "- GLM's allow us to express relationships in a linear and additive way like normal linear regression.\n",
    "- However, it might be the case that the underlying true relationship is neither linear nor additive. \n",
    "- The transformation is done through a *link function* (in this case, Poisson)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:        passenger_count   No. Observations:                98507\n",
      "Model:                            GLM   Df Residuals:                    98503\n",
      "Model Family:                 Poisson   Df Model:                            3\n",
      "Link Function:                    log   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -1.4793e+05\n",
      "Date:                Mon, 07 Jun 2021   Deviance:                       67982.\n",
      "Time:                        13:40:06   Pearson chi2:                 8.34e+04\n",
      "No. Iterations:                     5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            0.7066      0.005    137.411      0.000       0.696       0.717\n",
      "VendorID[T.True]    -0.4021      0.005    -79.627      0.000      -0.412      -0.392\n",
      "total_amount        -0.0001      0.001     -0.258      0.796      -0.001       0.001\n",
      "trip_distance       -0.0003      0.002     -0.163      0.871      -0.004       0.003\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.api import families\n",
    "\n",
    "# convert VendorID to categorical\n",
    "df['VendorID'] = df['VendorID'] == 1\n",
    "\n",
    "fit = glm(formula=\"passenger_count ~ total_amount + trip_distance + VendorID\",\n",
    "         data=df, family=families.Poisson()).fit()\n",
    "\n",
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that `total_amount` is insignificant (`p-val=0.124>0.05`)\n",
    "- Conclude that the total fare amount does not really affect the number of passengers in a trip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "- What is the Bias-Variance tradeoff with respect to linear models:\n",
    "    - Less parameters = less variance but more bias\n",
    "    - More parameters = more variaance but less bias\n",
    "    - The goal depends on the problem, but generalled we want an even variaance and bias (intersection).\n",
    "\n",
    "- Is using regression on X attribute / specific dataset even a good choice...?\n",
    "    - The answer is yes, it is a good choice *to try*\n",
    "    - BUT also try other methods...\n",
    "    \n",
    "    \n",
    "- What are the pros and cons of stepwise regression?\n",
    "    - Forward Selection (start from nothing and end until significant)\n",
    "    - Backward Elimination (start with everything and end until no more can be removed)\n",
    "    - Not always the best results...\n",
    "    \n",
    "    \n",
    "- What is best subset regression and the pros and cons of it?\n",
    "    - A brute-force like method of fitting *all posssible regressuibs* or *all possible models*\n",
    "    - Unlike stepwise, this method fits all possible models based on the variables specified, so you will get the best model possible\n",
    "    ![test](https://i.kym-cdn.com/photos/images/newsfeed/001/718/138/147.jpg)\n",
    "    \n",
    "    \n",
    "    \n",
    "- What is an assumption we make when we fit linear regression models?\n",
    "    - Well, the data has to be linearly seperable. \n",
    "    - Does this also apply to other models too...? (Recall SVM and kernel function which we can use)\n",
    "    - Perhaps another model might suit the dataset... (Trees, Neural Networks, Clustering, etc...)\n",
    "    \n",
    "    \n",
    "- If you were to use a decision tree, how would you compare between two different fits? \n",
    "    - Look at Gini Impurity (probability of an incorrectly classified instance)\n",
    "    \n",
    "\n",
    "- How about baselines or other predictive machine learning models?\n",
    "    - Precision, Recall, Classification Accuracy..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering?\n",
    "- We want to see if the the profitability of zones remains consistent with respect to hour of day, day of week and pickup location. The distribution of profitable zones should be similar across all years.\n",
    "- How is a zone profitable? Frequency of trips? Duration of trips? Best \"earners\"? \n",
    "\n",
    "- You could create your own feature and scale it accordingly. Perhaps the expected dollar per minute + possible tolls scaled by the expected frequency of trips might be a good start.\n",
    "\n",
    "- Just remember that trip frequency $\\approx$ taxi demand in a zone (you don't know the number of taxis in a zone at the time)\n",
    "\n",
    "- Additionally, variable rate fares exist: *\"50 cents per 1/5 mile when travelling above 12mph OR 50 cents per 60 seconds in slow traffic or when the vehicle is stopped.\"*\n",
    "\n",
    "- Profit rates might assume crude approximations degrading into linear distance / constant velocity / etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Requisite Tasks for the Apache Spark tutorial\n",
    "\n",
    "### WSL Environment for Windows 10\n",
    "Refer to this guide to get a native Linux terminal in Windows 10:\n",
    "- https://github.com/akiratwang/COMP20003-Setting-Up\n",
    "- Ignore all the `C` related parts, just get Ubuntu installed.\n",
    "\n",
    "### Apache Spark 3.0 (PySpark) Installation\n",
    "- Visit `MAST30034/advanced_tutorials/Spark%20Installation.ipynb`\n",
    "\n",
    "## Today\n",
    "### Apache Spark 3.0 (PySpark and Spark SQL) Tutorial - Continued\n",
    "- Visit `MAST30034/advanced_tutorials/Spark%20Tutorial.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
